{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read movielens\n",
    "ratings = pd.read_csv('raw_data/ratings.csv')\n",
    "links = pd.read_csv('raw_data/links.csv')\n",
    "\n",
    "# get list of movies that have ratings\n",
    "movie_ids = ratings['movieId'].unique()\n",
    "\n",
    "# get list of imdb ids from movie ids\n",
    "valid_movie_ids = links['movieId'].isin(movie_ids)\n",
    "imdb_ids = links[valid_movie_ids]['imdbId'].tolist()\n",
    "imdb_ids = links['imdbId'].tolist()\n",
    "\n",
    "# add leading 0s to 6 digit ids\n",
    "imdb_ids = [str(num).zfill(7) for num in imdb_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read imdb5000 merged\n",
    "metadata_raw = pd.read_csv('raw_data/movie_metadata.csv')\n",
    "\n",
    "# get merged of movies that have ratings\n",
    "metadata = metadata_raw[metadata_raw['movie_imdb_link'].str[28:35].isin(imdb_ids)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read posters\n",
    "posters = pd.read_csv('raw_data/movie_posters.csv', encoding='latin1')\n",
    "\n",
    "# get posters that have movies with user ratings\n",
    "posters['imdbId'] = posters['imdbId'].astype(str).str.zfill(7)\n",
    "posters = posters[posters['imdbId'].isin(imdb_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        https://images-na.ssl-images-amazon.com/images...\n",
      "1        https://images-na.ssl-images-amazon.com/images...\n",
      "2        https://images-na.ssl-images-amazon.com/images...\n",
      "3        https://images-na.ssl-images-amazon.com/images...\n",
      "4        https://images-na.ssl-images-amazon.com/images...\n",
      "                               ...                        \n",
      "39921    https://images-na.ssl-images-amazon.com/images...\n",
      "39944    https://images-na.ssl-images-amazon.com/images...\n",
      "40004    https://images-na.ssl-images-amazon.com/images...\n",
      "40013    https://images-na.ssl-images-amazon.com/images...\n",
      "40067    https://images-na.ssl-images-amazon.com/images...\n",
      "Name: Poster, Length: 9516, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(posters['Poster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read plots\n",
    "plots = pd.read_csv('raw_data/movie_plots.csv')\n",
    "\n",
    "# get movie titles\n",
    "# titles = [title[:-1] for title in merged['movie_title'].values]\n",
    "\n",
    "# get plots only from valid movie titles\n",
    "# plots = plots[plots['Title'].isin(titles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§© Merged rows: 3750, columns: 30\n",
      "   color      director_name  num_critic_for_reviews  duration  \\\n",
      "0  Color      James Cameron                   723.0     178.0   \n",
      "1  Color     Gore Verbinski                   302.0     169.0   \n",
      "2  Color         Sam Mendes                   602.0     148.0   \n",
      "3  Color         Sam Mendes                   602.0     148.0   \n",
      "4  Color  Christopher Nolan                   813.0     164.0   \n",
      "\n",
      "   director_facebook_likes  actor_3_facebook_likes      actor_2_name  \\\n",
      "0                      0.0                   855.0  Joel David Moore   \n",
      "1                    563.0                  1000.0     Orlando Bloom   \n",
      "2                      0.0                   161.0      Rory Kinnear   \n",
      "3                      0.0                   161.0      Rory Kinnear   \n",
      "4                  22000.0                 23000.0    Christian Bale   \n",
      "\n",
      "   actor_1_facebook_likes        gross                           genres  ...  \\\n",
      "0                  1000.0  760505847.0  Action|Adventure|Fantasy|Sci-Fi  ...   \n",
      "1                 40000.0  309404152.0         Action|Adventure|Fantasy  ...   \n",
      "2                 11000.0  200074175.0        Action|Adventure|Thriller  ...   \n",
      "3                 11000.0  200074175.0        Action|Adventure|Thriller  ...   \n",
      "4                 27000.0  448130642.0                  Action|Thriller  ...   \n",
      "\n",
      "  country content_rating       budget  title_year actor_2_facebook_likes  \\\n",
      "0     USA          PG-13  237000000.0      2009.0                  936.0   \n",
      "1     USA          PG-13  300000000.0      2007.0                 5000.0   \n",
      "2      UK          PG-13  245000000.0      2015.0                  393.0   \n",
      "3      UK          PG-13  245000000.0      2015.0                  393.0   \n",
      "4     USA          PG-13  250000000.0      2012.0                23000.0   \n",
      "\n",
      "   imdb_score aspect_ratio movie_facebook_likes  \\\n",
      "0         7.9         1.78                33000   \n",
      "1         7.1         2.35                    0   \n",
      "2         6.8         2.35                85000   \n",
      "3         6.8         2.35                85000   \n",
      "4         8.5         2.35               164000   \n",
      "\n",
      "                                title_clean  \\\n",
      "0                                    avatar   \n",
      "1  pirates of the caribbean: at world's end   \n",
      "2                                   spectre   \n",
      "3                                   spectre   \n",
      "4                     the dark knight rises   \n",
      "\n",
      "                                                Plot  \n",
      "0  In 2154, humans have depleted Earth's natural ...  \n",
      "1  In order to control the oceans, Lord Cutler Be...  \n",
      "2  William Sebastian (Robert Culp) is a former cr...  \n",
      "3  A posthumous message from the previous M leads...  \n",
      "4  Eight years after the death of District Attorn...  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create cleaned title columns first if not done already\n",
    "metadata['title_clean'] = metadata['movie_title'].str.lower().str.strip().str.replace(r'\\xa0', '', regex=True)\n",
    "plots['title_clean'] = plots['Title'].str.lower().str.strip()\n",
    "\n",
    "# Only keep the columns you care about from plots\n",
    "plots_subset = plots[['title_clean', 'Plot']]\n",
    "\n",
    "# Merge just Plot into merged\n",
    "merged = pd.merge(metadata, plots_subset, on='title_clean', how='inner')\n",
    "\n",
    "print(f\"ðŸ§© Merged rows: {merged.shape[0]}, columns: {merged.shape[1]}\")\n",
    "print(merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All genres found: {'Family', 'Musical', 'Music', 'Crime', 'Drama', 'Romance', 'War', 'Documentary', 'Horror', 'Biography', 'Sport', 'Film-Noir', 'Thriller', 'Comedy', 'Fantasy', 'Adventure', 'Mystery', 'Sci-Fi', 'Western', 'Animation', 'History', 'Action'}\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split genres by '|' and explode them into sets\n",
    "genres_split = merged['genres'].fillna('').apply(lambda x: [genre for genre in x.split('|') if genre]).copy()\n",
    "\n",
    "# Step 2: Get list of all unique genres\n",
    "from itertools import chain\n",
    "\n",
    "all_genres = set(chain.from_iterable(genres_split))\n",
    "all_genres.discard('')\n",
    "print(\"All genres found:\", all_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   genre_family  genre_musical  genre_music  genre_crime  genre_drama  \\\n",
      "0             0              0            0            0            0   \n",
      "1             0              0            0            0            0   \n",
      "2             0              0            0            0            0   \n",
      "3             0              0            0            0            0   \n",
      "4             0              0            0            0            0   \n",
      "\n",
      "   genre_romance  genre_war  genre_documentary  genre_horror  genre_biography  \\\n",
      "0              0          0                  0             0                0   \n",
      "1              0          0                  0             0                0   \n",
      "2              0          0                  0             0                0   \n",
      "3              0          0                  0             0                0   \n",
      "4              0          0                  0             0                0   \n",
      "\n",
      "   ...  genre_thriller  genre_comedy  genre_fantasy  genre_adventure  \\\n",
      "0  ...               0             0              1                1   \n",
      "1  ...               0             0              1                1   \n",
      "2  ...               1             0              0                1   \n",
      "3  ...               1             0              0                1   \n",
      "4  ...               1             0              0                0   \n",
      "\n",
      "   genre_mystery  genre_sci-fi  genre_western  genre_animation  genre_history  \\\n",
      "0              0             1              0                0              0   \n",
      "1              0             0              0                0              0   \n",
      "2              0             0              0                0              0   \n",
      "3              0             0              0                0              0   \n",
      "4              0             0              0                0              0   \n",
      "\n",
      "   genre_action  \n",
      "0             1  \n",
      "1             1  \n",
      "2             1  \n",
      "3             1  \n",
      "4             1  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create one hots for each genre\n",
    "for genre in all_genres:\n",
    "    if not genre.strip():  # Skip empty strings\n",
    "        continue\n",
    "    merged.loc[:,f'genre_{genre.lower()}'] = genres_split.apply(lambda genres: int(genre in genres))\n",
    "\n",
    "genre_cols = [col for col in merged.columns if col.startswith('genre_')]\n",
    "print(merged[genre_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'plot_keywords' in merged:\n",
    "    plot_keywords = merged['plot_keywords'].copy()\n",
    "\n",
    "if 'movie_title' in merged:\n",
    "    titles = merged['movie_title'].values\n",
    "\n",
    "merged['imdbId'] = merged['movie_imdb_link'].str.extract(r'(\\d{7})')\n",
    "\n",
    "DROPPED_COLS = ['genres', 'color', 'movie_imdb_link', 'plot_keywords', 'movie_title']\n",
    "merged.drop(columns=DROPPED_COLS, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No empty cols: True\n"
     ]
    }
   ],
   "source": [
    "fill_unknown = ['director_name', 'actor_2_name', 'actor_3_name', 'language', 'content_rating']\n",
    "merged[fill_unknown] = merged[fill_unknown].fillna('Unknown')\n",
    "\n",
    "plot_keywords = plot_keywords.fillna('')\n",
    "merged['duration'] = merged['duration'].fillna(merged['duration'].median())\n",
    "merged['director_facebook_likes'] = merged['director_facebook_likes'].fillna(0)\n",
    "merged['actor_3_facebook_likes'] = merged['actor_3_facebook_likes'].fillna(0)\n",
    "merged['gross'] = merged['gross'].fillna(merged['gross'].median())  # or 0\n",
    "merged['facenumber_in_poster'] = merged['facenumber_in_poster'].fillna(0)\n",
    "merged['budget'] = merged['budget'].fillna(merged['budget'].median())  # or 0\n",
    "merged['title_year'] = merged['title_year'].fillna(merged['title_year'].median())\n",
    "merged['actor_2_facebook_likes'] = merged['actor_2_facebook_likes'].fillna(0)\n",
    "merged['aspect_ratio'] = merged['aspect_ratio'].fillna(merged['aspect_ratio'].median())\n",
    "\n",
    "print(\"No empty cols:\", merged.isnull().sum().sum() == 0)\n",
    "# null_counts = merged.isnull().sum()\n",
    "# print(null_counts[null_counts > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tim\\Anaconda3\\envs\\sceneit-env\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create TFIDF vectors for the plot keywords, then use Truncated SVD to create dense embeddings\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    tokenizer=lambda x: x.split('|'),\n",
    "    max_features=1000  # Limit to top 1000 most frequent\n",
    ")\n",
    "\n",
    "plot_keywords_tfidf = tfidf.fit_transform(plot_keywords.fillna(''))\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, random_state=42)  # You can change dimensions\n",
    "plot_keywords_dense = svd.fit_transform(plot_keywords_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "embedding_cols = [\n",
    "    'director_name', 'actor_1_name', 'actor_2_name', 'actor_3_name',\n",
    "    'language', 'country', 'content_rating'\n",
    "]\n",
    "\n",
    "for col in embedding_cols:\n",
    "    merged[col] = LabelEncoder().fit_transform(merged[col])\n",
    "\n",
    "numerical_cols = [\n",
    "    'num_critic_for_reviews', 'duration', 'director_facebook_likes',\n",
    "    'actor_3_facebook_likes', 'actor_1_facebook_likes', 'gross',\n",
    "    'num_voted_users', 'cast_total_facebook_likes', 'facenumber_in_poster',\n",
    "    'num_user_for_reviews', 'budget', 'title_year', 'actor_2_facebook_likes',\n",
    "    'imdb_score', 'aspect_ratio', 'movie_facebook_likes'\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "merged[numerical_cols] = scaler.fit_transform(merged[numerical_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed posters: 1740\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os\n",
    "\n",
    "os.makedirs(\"posters\", exist_ok=True)\n",
    "\n",
    "posters = pd.read_csv('./clean_data/posters.csv')['Poster'].copy()\n",
    "urls = posters.tolist()\n",
    "\n",
    "failed = []\n",
    "for i, url in enumerate(urls):\n",
    "    try:\n",
    "        filename = f\"posters/{i}.jpg\"\n",
    "        if os.path.exists(filename):\n",
    "            continue  # Skip if already downloaded\n",
    "\n",
    "        response  = requests.get(url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        img = img.resize((224, 224))\n",
    "        img.save(filename)\n",
    "    except Exception as e:\n",
    "        # print(f\"Failed to download poster {i} with {url}: {e}\")\n",
    "        failed.append((i, url))\n",
    "\n",
    "print(f\"Failed posters: {len(failed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle movies with errors\n",
    "for i, movie in enumerate(failed):\n",
    "    movie_id = failed[i][0]\n",
    "    filename = f\"posters/{movie_id}.jpg\"\n",
    "    if os.path.exists(filename):\n",
    "        continue  # Skip if already downloaded\n",
    "    blank_image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "    blank_image.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'movie_imdb_link'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\Anaconda3\\envs\\sceneit-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'movie_imdb_link'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./clean_data/posters.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimdbId\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimdbId\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m7\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m merged[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimdbId\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mmerged\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmovie_imdb_link\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m{7}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# after merging posters, metadata, and plots\u001b[39;00m\n\u001b[0;32m      8\u001b[0m merged \u001b[38;5;241m=\u001b[39m merged\u001b[38;5;241m.\u001b[39mmerge(df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimdbId\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\sceneit-env\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\sceneit-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'movie_imdb_link'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./clean_data/posters.csv').copy()\n",
    "\n",
    "df['imdbId'] = df['imdbId'].astype(str).str.zfill(7)\n",
    "merged['imdbId'] = merged['movie_imdb_link'].str.extract(r'(\\d{7})')\n",
    "\n",
    "\n",
    "# after merging posters, metadata, and plots\n",
    "merged = merged.merge(df, on='imdbId', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add model here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Model Implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
